{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perimeter Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file(\"ca_camp_20181108_1754_dd83.shp\")\n",
    "shapefile.shape\n",
    "shapefile[\"perDatTime\"][0]\n",
    "#print(shapefile)\n",
    "for i in range(24):\n",
    "    print(shapefile.columns[i])\n",
    "\n",
    "shapefile2 = gpd.read_file(\"./2009_Fires/2009_Fires.shp\")\n",
    "shapefile3 = gpd.read_file(\"./US_HIST_FIRE_PERIMTRS_DD83-3/US_HIST_FIRE_PERIMTRS_DD83.shp\")\n",
    "#print(shapefile2)\n",
    "\n",
    "##Visualizing columns\n",
    "shapefile3 = gpd.read_file(\"./2000_perimeters_dd83/2000_perimeters_dd83.shp\")\n",
    "print(shapefile3.columns)\n",
    "print(shapefile3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/2019_fire_data'\n",
    "url2 = 'https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/2019_fire_data/Alabama/'\n",
    "https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/2019_fire_data/Alabama/\n",
    "response = requests.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "soup.findAll('a')\n",
    "one_a_tag = soup.findAll('a')[0]\n",
    "link = one_a_tag['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of urls of fire perimeters for all states for 2019\n",
    "def getStateUrls():\n",
    "    url = 'https://rmgsc.cr.usgs.gov/outgoing/GeoMAC/2019_fire_data'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #soup.findAll('a')\n",
    "\n",
    "    state_urls = []\n",
    "    line_count = 0\n",
    "    for i,eachtag in enumerate(soup.findAll('a')):\n",
    "        if i >0:\n",
    "            statelink = eachtag['href']\n",
    "            state_url = 'https://rmgsc.cr.usgs.gov' + statelink\n",
    "            state_urls.append(state_url)\n",
    "    return state_urls\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_urls = getStateUrls()\n",
    "\n",
    "#clean some stateurls\n",
    "prob1 = state_urls[6]\n",
    "prob2 = state_urls[13]\n",
    "prob3 = state_urls[14]\n",
    "prob4 = state_urls[9]\n",
    "state_urls.remove(prob1)\n",
    "state_urls.remove(prob2)\n",
    "state_urls.remove(prob3)\n",
    "state_urls.remove(prob4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading all perimeter files for 2019 across all state urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This assumes you create a 'GeomacData' folder in your current directory to store these files.\n",
    "for eachstateurl in state_urls:\n",
    "    urlnew = eachstateurl\n",
    "    response = requests.get(urlnew)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    suburls_hrefs = soup.findAll('a')\n",
    "    suburls_actual = [element['href'] for element in suburls_hrefs] \n",
    "    for i,suburl in enumerate(suburls_actual):    #for each fire url in state folder\n",
    "        if i>0:\n",
    "            #print(suburl)\n",
    "            firelink = 'https://rmgsc.cr.usgs.gov' + suburl\n",
    "            response = requests.get(firelink)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")  \n",
    "            fire_evols = soup.findAll('a')   #list of shape files links in the fire's page.\n",
    "            fire_shp_files = [element['href'] for element in fire_evols] \n",
    "            for j,fire_evol in enumerate(fire_shp_files):\n",
    "                if j>0:\n",
    "                    download_url = 'https://rmgsc.cr.usgs.gov' + fire_evol\n",
    "                    storeurl = './GeomacData/'+ fire_evol.split(\"/\")[-1]\n",
    "                    urllib.request.urlretrieve(download_url,storeurl) \n",
    "                    time.sleep(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas\n",
    "import geopandas\n",
    "\n",
    "folder = Path(\"./GeomacData\")\n",
    "shapefiles = folder.glob(\"*.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shp in shapefiles:\n",
    "        print(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "file = os.listdir(\"./GeomacData\")\n",
    "path = [os.path.join(\"./GeomacData\", i) for i in file if i.endswith('.shp')]\n",
    "#tester =[each for each in os.listdir(folder) if each.endswith('.shp')]\n",
    "gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in path], \n",
    "                        ignore_index=True), crs=gpd.read_file(path[0]).crs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = gdf.copy()  #duplicate\n",
    "\n",
    "### CLEANING COLUMNS OF MERGED DATA.\n",
    "#df['feedback_id'].combine_first(df['_id'])\n",
    "gdf2['perDatTime'] = gdf2['perDatTime'].combine_first(gdf['PERDATTIME'])\n",
    "gdf2['fireName'] = gdf2['perDatTime'].combine_first(gdf['PERDATTIME'])\n",
    "gdf2['fireNum'] = gdf2['perDatTime'].combine_first(gdf['PERDATTIME'])\n",
    "gdf2['fireYear'] = gdf2['perDatTime'].combine_first(gdf['PERDATTIME'])\n",
    "gdf2['irwinid'] = gdf2['irwinid'].combine_first(gdf['IRWINID'])\n",
    "gdf2['state'] = gdf2['state'].combine_first(gdf['STATE'])\n",
    "gdf2['gisAcres'] = gdf2['gisAcres'].combine_first(gdf['GISACRES'])\n",
    "gdf2['incidentID'] = gdf2['incidentID'].combine_first(gdf['INCIDENTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2.to_file(\"results.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with saved Perimeter File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gpd.read_file(\"results.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.columns   #see column names, sometimes they change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gp['geometry'].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8/21/2019 4:29:27 PM'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.head()['perDatTi_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4:29:27 PM'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = gp.head()['perDatTi_1'][0]\n",
    "year = a[:9]\n",
    "time = a[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Sentinel Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owslib.wms import WebMapService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms = WebMapService('http://services.sentinel-hub.com/ogc/wms/45271f49-0dcb-4329-8b35-8b6508fee50b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary exploration of WMS options/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wms.identification.type\n",
    "wms.identification.version\n",
    "wms.identification.title\n",
    "wms.identification.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wms.contents)  #see list of options for types of data we can get.\n",
    "#wms['0'].title\n",
    "#wms['0'].styles\n",
    "#wms['0'].boundingBox\n",
    "#wms['0'].crsOptions\n",
    "#wms['0'].boundingBoxWGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms['TRUE_COLOR'].styles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[op.name for op in wms.operations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms.getOperationByName('GetMap').methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms.getOperationByName('GetMap').formatOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample format\n",
    "img = wms.getmap(    layers=['NDVI_GREEN_GRAY'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=(-112.918670, 40.811920, -112.909857, 40.818094),\n",
    "                     size=(300, 250),\n",
    "                     format='image/png',\n",
    "                     time ='2019-08-16/2019-08-21/P1D',                   \n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Retrieval Using Downloaded Perimeter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample with first element of polygon dataframe\n",
    "polygon = gp.head()['geometry'][0]\n",
    "import shapely\n",
    "\n",
    "\n",
    "ade = polygon.simplify(0.1, preserve_topology=True)  #simplify polygon to have fewer sides.\n",
    "print(ade)\n",
    "print(ade.bounds)  #coordinates of bounding box of that polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = wms.getmap(    layers=['TRUE_COLOR'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=ade.bounds,\n",
    "                     size=(300, 250),\n",
    "                     #geometry = ade,\n",
    "                     format='image/png',\n",
    "                     #Transparent = False,\n",
    "                     time ='2019-08-10/2019-08-21/P1D',                   \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save downloaded image as whatevername.png\n",
    "out = open('sentineltest8.png', 'wb')  #\n",
    "out.write(img2.read())\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Potential loop code for all shapes. Untested code\n",
    "\n",
    "def getDownloadImage(polygonbounds, timeparams, isFire, year):\n",
    "    \n",
    "    img2 = wms.getmap(layers=['TRUE_COLOR'],\n",
    "                     styles=['default'],\n",
    "                     srs='EPSG:4326',\n",
    "                     bbox=polygonbounds,\n",
    "                     size=(256, 256),  \n",
    "                     format='image/png',\n",
    "                     time =timeparams,                   \n",
    "                     )\n",
    "    \n",
    "    filename = 'sentinel' + year + isFire + '.png'\n",
    "    out = open(filename, 'wb')  #\n",
    "    out.write(img2.read())\n",
    "    out.close()\n",
    "    \n",
    "def getSearchInterval(gp,i):\n",
    "    from datetime import datetime\n",
    "    firedate = gp.head()['perDatTi_1'][i]\n",
    "    fireyear = firedate[:9]\n",
    "    todaysdate = datetime.strptime(fireyear, '%m/%d/%Y')\n",
    "    todaystr = todaysdate.strftime(\"%Y-%m-%d\")\n",
    "    import datetime\n",
    "    enddate = todaysdate + datetime.timedelta(days=10)  #can reduce\n",
    "    enddatenow = enddate.now()\n",
    "    enddatestr = enddatenow.strftime(\"%Y-%m-%d\")\n",
    "    search_interval = todaystr + '/' + enddatestr + '/' + 'P1D'\n",
    "    return (search_interval, todaysdate.strftime(\"%Y\"))\n",
    "    \n",
    "def downloadAllBurnImages(gp):\n",
    "    isFire = 1\n",
    "    for i in range(len(gp)):\n",
    "        polygon = gp.head()['geometry'][i]\n",
    "        polygon_simple = polygon.simplify(0.1, preserve_topology=True) \n",
    "        polygonbounds = polygon_simple.bounds\n",
    "        (timeparams, year) = getSearchInterval(gp,i)\n",
    "        getDownloadImage(polygonbounds, timeparams, isFire, year)\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadAllBurnImages(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
